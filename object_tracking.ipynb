{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Система отслеживания объектов на основе ключевых точек\n",
    "\n",
    "Этот проект реализует простой алгоритм трекинга объекта на видео с использованием детекции ключевых точек ORB и сопоставления признаков.\n",
    "\n",
    "## Алгоритм работы:\n",
    "1. Детекция ключевых точек на первом кадре (объект)\n",
    "2. Поиск соответствующих точек на последующих кадрах\n",
    "3. Вычисление гомографии для определения положения объекта\n",
    "4. Рисование рамки вокруг отслеживаемого объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video, display\n",
    "import os\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "print(\"Библиотеки успешно импортированы!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Класс для отслеживания объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTracker:\n",
    "    \"\"\"\n",
    "    Класс для отслеживания объектов на основе ключевых точек\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_matches=10, ransac_threshold=5.0):\n",
    "        \"\"\"\n",
    "        Инициализация трекера\n",
    "        \n",
    "        Args:\n",
    "            min_matches: Минимальное количество совпадений\n",
    "            ransac_threshold: Порог для RANSAC\n",
    "        \"\"\"\n",
    "        self.min_matches = min_matches\n",
    "        self.ransac_threshold = ransac_threshold\n",
    "        \n",
    "        # Инициализация детектора ORB\n",
    "        self.orb = cv2.ORB_create(nfeatures=1000)\n",
    "        \n",
    "        # Инициализация сопоставителя\n",
    "        self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        \n",
    "        # Переменные для хранения состояния\n",
    "        self.object_kp = None\n",
    "        self.object_desc = None\n",
    "        self.object_bbox = None\n",
    "        self.is_initialized = False\n",
    "        \n",
    "    def initialize(self, frame: np.ndarray, bbox: Tuple[int, int, int, int]) -> bool:\n",
    "        \"\"\"\n",
    "        Инициализация объекта на первом кадре\n",
    "        \n",
    "        Args:\n",
    "            frame: Первый кадр видео\n",
    "            bbox: Ограничивающая рамка (x, y, width, height)\n",
    "            \n",
    "        Returns:\n",
    "            True если инициализация успешна\n",
    "        \"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        \n",
    "        # Проверка корректности рамки\n",
    "        if x < 0 or y < 0 or x + w > frame.shape[1] or y + h > frame.shape[0]:\n",
    "            print(\"Ошибка: некорректные координаты рамки\")\n",
    "            return False\n",
    "        \n",
    "        # Извлечение области объекта\n",
    "        object_roi = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Детекция ключевых точек и вычисление дескрипторов\n",
    "        self.object_kp, self.object_desc = self.orb.detectAndCompute(object_roi, None)\n",
    "        \n",
    "        if len(self.object_kp) < self.min_matches:\n",
    "            print(f\"Ошибка: недостаточно ключевых точек ({len(self.object_kp)} < {self.min_matches})\")\n",
    "            return False\n",
    "        \n",
    "        self.object_bbox = bbox\n",
    "        self.is_initialized = True\n",
    "        \n",
    "        print(f\"Объект инициализирован: {len(self.object_kp)} ключевых точек\")\n",
    "        return True\n",
    "    \n",
    "    def update(self, frame: np.ndarray) -> Tuple[bool, Tuple[int, int, int, int]]:\n",
    "        \"\"\"\n",
    "        Обновление положения объекта на текущем кадре\n",
    "        \n",
    "        Args:\n",
    "            frame: Текущий кадр\n",
    "            \n",
    "        Returns:\n",
    "            (success, bbox) - успех отслеживания и новая рамка\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            return False, (0, 0, 0, 0)\n",
    "        \n",
    "        # Детекция ключевых точек на текущем кадре\n",
    "        frame_kp, frame_desc = self.orb.detectAndCompute(frame, None)\n",
    "        \n",
    "        if frame_desc is None or len(frame_kp) < self.min_matches:\n",
    "            return False, self.object_bbox\n",
    "        \n",
    "        # Сопоставление признаков\n",
    "        matches = self.matcher.match(self.object_desc, frame_desc)\n",
    "        \n",
    "        if len(matches) < self.min_matches:\n",
    "            return False, self.object_bbox\n",
    "        \n",
    "        # Сортировка совпадений по расстоянию\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        \n",
    "        # Подготовка точек для вычисления гомографии\n",
    "        obj_pts = np.float32([self.object_kp[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        scene_pts = np.float32([frame_kp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Вычисление гомографии\n",
    "        homography, mask = cv2.findHomography(\n",
    "            obj_pts, scene_pts, \n",
    "            cv2.RANSAC, \n",
    "            self.ransac_threshold\n",
    "        )\n",
    "        \n",
    "        if homography is None:\n",
    "            return False, self.object_bbox\n",
    "        \n",
    "        # Преобразование углов рамки объекта\n",
    "        x, y, w, h = self.object_bbox\n",
    "        obj_corners = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)\n",
    "        \n",
    "        try:\n",
    "            scene_corners = cv2.perspectiveTransform(obj_corners, homography)\n",
    "            \n",
    "            # Вычисление новой ограничивающей рамки\n",
    "            x_coords = [corner[0][0] for corner in scene_corners]\n",
    "            y_coords = [corner[0][1] for corner in scene_corners]\n",
    "            \n",
    "            new_x = int(min(x_coords))\n",
    "            new_y = int(min(y_coords))\n",
    "            new_w = int(max(x_coords) - new_x)\n",
    "            new_h = int(max(y_coords) - new_y)\n",
    "            \n",
    "            # Проверка корректности новой рамки\n",
    "            if new_w > 0 and new_h > 0:\n",
    "                self.object_bbox = (new_x, new_y, new_w, new_h)\n",
    "                return True, self.object_bbox\n",
    "            else:\n",
    "                return False, self.object_bbox\n",
    "                \n",
    "        except:\n",
    "            return False, self.object_bbox\n",
    "    \n",
    "    def visualize(self, frame: np.ndarray, show_keypoints: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Визуализация результатов отслеживания\n",
    "        \n",
    "        Args:\n",
    "            frame: Текущий кадр\n",
    "            show_keypoints: Показывать ключевые точки\n",
    "            \n",
    "        Returns:\n",
    "            Кадр с визуализацией\n",
    "        \"\"\"\n",
    "        vis_frame = frame.copy()\n",
    "        \n",
    "        if self.is_initialized and self.object_bbox:\n",
    "            x, y, w, h = self.object_bbox\n",
    "            \n",
    "            # Рисование рамки\n",
    "            cv2.rectangle(vis_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Добавление текста\n",
    "            cv2.putText(vis_frame, \"Tracked Object\", (x, y - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        return vis_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Функции для обработки видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path: str, output_path: str = None, \n",
    "                 initial_bbox: Tuple[int, int, int, int] = None,\n",
    "                 show_keypoints: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Обработка видео с отслеживанием объекта\n",
    "    \n",
    "    Args:\n",
    "        video_path: Путь к входному видео\n",
    "        output_path: Путь для сохранения результата\n",
    "        initial_bbox: Начальная рамка объекта\n",
    "        show_keypoints: Показывать ключевые точки\n",
    "        \n",
    "    Returns:\n",
    "        Словарь с результатами обработки\n",
    "    \"\"\"\n",
    "    \n",
    "    # Открытие видео\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Не удалось открыть видео: {video_path}\")\n",
    "    \n",
    "    # Получение информации о видео\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Информация о видео:\")\n",
    "    print(f\"  Разрешение: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Всего кадров: {total_frames}\")\n",
    "    \n",
    "    # Настройка видеозаписи\n",
    "    writer = None\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Создание трекера\n",
    "    tracker = ObjectTracker()\n",
    "    \n",
    "    # Чтение первого кадра\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        raise ValueError(\"Не удалось прочитать первый кадр\")\n",
    "    \n",
    "    # Получение начальной рамки\n",
    "    if initial_bbox is None:\n",
    "        print(\"\\nВыберите объект для отслеживания на первом кадре\")\n",
    "        print(\"Используйте мышь для выделения области, затем нажмите ENTER\")\n",
    "        \n",
    "        # Отображение кадра для выбора\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Выберите объект для отслеживания\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # В Jupyter используем предопределенные координаты\n",
    "        print(\"В Jupyter Notebook используйте предопределенные координаты или передайте их в функцию\")\n",
    "        print(\"Пример: process_video('video.mp4', initial_bbox=(100, 100, 200, 150))\")\n",
    "        return None\n",
    "    \n",
    "    # Инициализация трекера\n",
    "    if not tracker.initialize(first_frame, initial_bbox):\n",
    "        raise ValueError(\"Не удалось инициализировать отслеживание\")\n",
    "    \n",
    "    # Переменные для статистики\n",
    "    frame_count = 0\n",
    "    successful_tracks = 0\n",
    "    tracking_results = []\n",
    "    \n",
    "    # Обработка кадров\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Обновление отслеживания\n",
    "        success, bbox = tracker.update(frame)\n",
    "        \n",
    "        if success:\n",
    "            successful_tracks += 1\n",
    "        \n",
    "        # Визуализация\n",
    "        vis_frame = tracker.visualize(frame, show_keypoints)\n",
    "        \n",
    "        # Сохранение результатов\n",
    "        tracking_results.append({\n",
    "            'frame': frame_count,\n",
    "            'success': success,\n",
    "            'bbox': bbox\n",
    "        })\n",
    "        \n",
    "        # Запись кадра\n",
    "        if writer:\n",
    "            writer.write(vis_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Вывод прогресса\n",
    "        if frame_count % 30 == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Обработка: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "    \n",
    "    # Освобождение ресурсов\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "    \n",
    "    # Вычисление статистики\n",
    "    success_rate = (successful_tracks / frame_count) * 100 if frame_count > 0 else 0\n",
    "    \n",
    "    results = {\n",
    "        'total_frames': frame_count,\n",
    "        'successful_tracks': successful_tracks,\n",
    "        'success_rate': success_rate,\n",
    "        'tracking_results': tracking_results\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nРезультаты обработки:\")\n",
    "    print(f\"  Всего кадров: {frame_count}\")\n",
    "    print(f\"  Успешно отслежено: {successful_tracks}\")\n",
    "    print(f\"  Успешность: {success_rate:.1f}%\")\n",
    "    \n",
    "    if output_path:\n",
    "        print(f\"  Видео сохранено: {output_path}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_video(output_path: str, duration: int = 10, fps: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Создание тестового видео с движущимся объектом\n",
    "    \n",
    "    Args:\n",
    "        output_path: Путь для сохранения видео\n",
    "        duration: Длительность в секундах\n",
    "        fps: Кадры в секунду\n",
    "        \n",
    "    Returns:\n",
    "        Путь к созданному видео\n",
    "    \"\"\"\n",
    "    width, height = 640, 480\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    total_frames = duration * fps\n",
    "    \n",
    "    for frame_num in range(total_frames):\n",
    "        # Создание фона\n",
    "        frame = np.ones((height, width, 3), dtype=np.uint8) * 50\n",
    "        \n",
    "        # Добавление текстуры\n",
    "        noise = np.random.randint(0, 100, (height, width, 3), dtype=np.uint8)\n",
    "        frame = cv2.add(frame, noise)\n",
    "        \n",
    "        # Создание движущегося объекта (книга с текстурой)\n",
    "        obj_width, obj_height = 120, 80\n",
    "        \n",
    "        # Движение по синусоиде\n",
    "        center_x = int(width/2 + 150 * np.sin(2 * np.pi * frame_num / (fps * 3)))\n",
    "        center_y = int(height/2 + 50 * np.cos(2 * np.pi * frame_num / (fps * 2)))\n",
    "        \n",
    "        x = center_x - obj_width // 2\n",
    "        y = center_y - obj_height // 2\n",
    "        \n",
    "        # Рисование объекта с текстурой\n",
    "        obj_roi = frame[y:y+obj_height, x:x+obj_width]\n",
    "        \n",
    "        # Добавление паттерна\n",
    "        for i in range(0, obj_width, 10):\n",
    "            cv2.line(obj_roi, (i, 0), (i, obj_height), (100, 150, 200), 2)\n",
    "        for i in range(0, obj_height, 10):\n",
    "            cv2.line(obj_roi, (0, i), (obj_width, i), (200, 150, 100), 2)\n",
    "        \n",
    "        # Добавление текста\n",
    "        cv2.putText(obj_roi, \"BOOK\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        writer.write(frame)\n",
    "    \n",
    "    writer.release()\n",
    "    print(f\"Тестовое видео создано: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def display_frame(frame: np.ndarray, title: str = \"Frame\"):\n",
    "    \"\"\"\n",
    "    Отображение кадра в Jupyter\n",
    "    \n",
    "    Args:\n",
    "        frame: Кадр для отображения\n",
    "        title: Заголовок\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_tracking_results(results: dict):\n",
    "    \"\"\"\n",
    "    Анализ результатов отслеживания\n",
    "    \n",
    "    Args:\n",
    "        results: Результаты отслеживания\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"Нет результатов для анализа\")\n",
    "        return\n",
    "    \n",
    "    # Извлечение данных\n",
    "    frames = [r['frame'] for r in results['tracking_results']]\n",
    "    successes = [r['success'] for r in results['tracking_results']]\n",
    "    \n",
    "    # Построение графика успешности\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(frames, successes, 'b-', alpha=0.7)\n",
    "    plt.title('Успешность отслеживания по кадрам')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Успешность (1=успех, 0=неудача)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Скользящее среднее\n",
    "    window_size = 10\n",
    "    if len(successes) > window_size:\n",
    "        moving_avg = []\n",
    "        for i in range(len(successes)):\n",
    "            start_idx = max(0, i - window_size + 1)\n",
    "            avg = sum(successes[start_idx:i+1]) / (i - start_idx + 1)\n",
    "            moving_avg.append(avg)\n",
    "        \n",
    "        plt.plot(frames, moving_avg, 'r-', linewidth=2, label=f'Скользящее среднее ({window_size} кадров)')\n",
    "        plt.legend()\n",
    "    \n",
    "    # Круговая диаграмма\n",
    "    plt.subplot(1, 2, 2)\n",
    "    success_count = results['successful_tracks']\n",
    "    failure_count = results['total_frames'] - success_count\n",
    "    \n",
    "    plt.pie([success_count, failure_count], \n",
    "            labels=['Успешно', 'Неудачно'], \n",
    "            colors=['green', 'red'], \n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "    plt.title('Общая успешность отслеживания')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nСтатистика отслеживания:\")\n",
    "    print(f\"  Всего кадров: {results['total_frames']}\")\n",
    "    print(f\"  Успешно: {results['successful_tracks']} ({results['success_rate']:.1f}%)\")\n",
    "    print(f\"  Неудачно: {results['total_frames'] - results['successful_tracks']} ({100-results['success_rate']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Тестирование системы\n",
    "\n",
    "### 5.1 Создание тестового видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание тестового видео\n",
    "test_video_path = \"test_videos/sample_video.mp4\"\n",
    "create_sample_video(test_video_path, duration=10, fps=30)\n",
    "\n",
    "# Проверка создания\n",
    "if os.path.exists(test_video_path):\n",
    "    print(f\"Тестовое видео создано: {test_video_path}\")\n",
    "    \n",
    "    # Отображение информации о видео\n",
    "    cap = cv2.VideoCapture(test_video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"  Разрешение: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Кадров: {frames}\")\n",
    "else:\n",
    "    print(\"Ошибка при создании тестового видео\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Тестирование отслеживания на созданном видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение начальной рамки для тестового видео\n",
    "# (центр видео, где находится объект в начале)\n",
    "initial_bbox = (260, 200, 120, 80)  # (x, y, width, height)\n",
    "\n",
    "# Обработка видео\n",
    "output_video_path = \"test_videos/tracked_output.mp4\"\n",
    "results = process_video(\n",
    "    video_path=test_video_path,\n",
    "    output_path=output_video_path,\n",
    "    initial_bbox=initial_bbox,\n",
    "    show_keypoints=False\n",
    ")\n",
    "\n",
    "if results:\n",
    "    print(\"\\nОтслеживание завершено успешно!\")\n",
    "else:\n",
    "    print(\"Ошибка при отслеживании\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ результатов отслеживания\n",
    "if results:\n",
    "    analyze_tracking_results(results)\n",
    "else:\n",
    "    print(\"Нет результатов для анализа\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Тестирование на реальных видео\n",
    "\n",
    "### 6.1 Загрузка и тестирование на пользовательском видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для тестирования пользовательского видео\n",
    "def test_custom_video(video_path: str, bbox: Tuple[int, int, int, int]):\n",
    "    \"\"\"\n",
    "    Тестирование отслеживания на пользовательском видео\n",
    "    \n",
    "    Args:\n",
    "        video_path: Путь к видео\n",
    "        bbox: Начальная рамка объекта\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Видео не найдено: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Тестирование видео: {video_path}\")\n",
    "    print(f\"Начальная рамка: {bbox}\")\n",
    "    \n",
    "    # Создание имени выходного файла\n",
    "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_path = f\"test_videos/tracked_{base_name}.mp4\"\n",
    "    \n",
    "    # Обработка видео\n",
    "    results = process_video(\n",
    "        video_path=video_path,\n",
    "        output_path=output_path,\n",
    "        initial_bbox=bbox,\n",
    "        show_keypoints=False\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        analyze_tracking_results(results)\n",
    "        return results\n",
    "    else:\n",
    "        print(\"Ошибка при обработке видео\")\n",
    "        return None\n",
    "\n",
    "# Пример использования (раскомментируйте для тестирования):\n",
    "# custom_results = test_custom_video(\"path/to/your/video.mp4\", (100, 100, 200, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сравнение разных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для сравнения разных параметров трекера\n",
    "def compare_parameters(video_path: str, bbox: Tuple[int, int, int, int]):\n",
    "    \"\"\"\n",
    "    Сравнение работы трекера с разными параметрами\n",
    "    \n",
    "    Args:\n",
    "        video_path: Путь к видео\n",
    "        bbox: Начальная рамка\n",
    "    \"\"\"\n",
    "    parameters = [\n",
    "        {'min_matches': 5, 'ransac_threshold': 3.0},\n",
    "        {'min_matches': 10, 'ransac_threshold': 5.0},\n",
    "        {'min_matches': 15, 'ransac_threshold': 8.0}\n",
    "    ]\n",
    "    \n",
    "    results_comparison = []\n",
    "    \n",
    "    for i, params in enumerate(parameters):\n",
    "        print(f\"\\nТестирование параметров {i+1}: {params}\")\n",
    "        \n",
    "        # Создание трекера с новыми параметрами\n",
    "        tracker = ObjectTracker(**params)\n",
    "        \n",
    "        # Обработка видео (упрощенная версия без сохранения)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        ret, first_frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # Инициализация\n",
    "        if not tracker.initialize(first_frame, bbox):\n",
    "            print(f\"Не удалось инициализировать трекер с параметрами {params}\")\n",
    "            continue\n",
    "        \n",
    "        # Обработка кадров\n",
    "        frame_count = 0\n",
    "        successful_tracks = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            success, _ = tracker.update(frame)\n",
    "            if success:\n",
    "                successful_tracks += 1\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        success_rate = (successful_tracks / frame_count) * 100 if frame_count > 0 else 0\n",
    "        \n",
    "        results_comparison.append({\n",
    "            'parameters': params,\n",
    "            'success_rate': success_rate,\n",
    "            'successful_tracks': successful_tracks,\n",
    "            'total_frames': frame_count\n",
    "        })\n",
    "        \n",
    "        print(f\"  Успешность: {success_rate:.1f}% ({successful_tracks}/{frame_count})\")\n",
    "    \n",
    "    # Визуализация сравнения\n",
    "    if results_comparison:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        param_labels = [f\"min_matches={r['parameters']['min_matches']}\\n\" \n",
    "                      f\"ransac={r['parameters']['ransac_threshold']}\" \n",
    "                      for r in results_comparison]\n",
    "        success_rates = [r['success_rate'] for r in results_comparison]\n",
    "        \n",
    "        bars = plt.bar(param_labels, success_rates, color=['blue', 'green', 'orange'])\n",
    "        \n",
    "        plt.title('Сравнение параметров трекера')\n",
    "        plt.ylabel('Успешность отслеживания (%)')\n",
    "        plt.ylim(0, 100)\n",
    "        \n",
    "        # Добавление значений на столбцы\n",
    "        for bar, rate in zip(bars, success_rates):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                    f'{rate:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results_comparison\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Сравнение параметров на тестовом видео\n",
    "comparison_results = compare_parameters(test_video_path, initial_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Выводы и рекомендации\n",
    "\n",
    "### Основные результаты:\n",
    "1. **Реализован алгоритм отслеживания** на основе ключевых точек ORB\n",
    "2. **Создана система визуализации** результатов отслеживания\n",
    "3. **Проведено тестирование** на синтетических и реальных видео\n",
    "4. **Выполнен анализ** производительности и надежности\n",
    "\n",
    "### Преимущества подхода:\n",
    "- **Инвариантность к вращению и масштабу** (ORB)\n",
    "- **Высокая скорость обработки** в реальном времени\n",
    "- **Устойчивость к изменению освещения**\n",
    "- **Простота реализации и настройки**\n",
    "\n",
    "### Ограничения:\n",
    "- **Требует текстурных объектов** для надежной детекции\n",
    "- **Проблемы при быстром движении** и размытии\n",
    "- **Сложности при частичной окклюзии** объекта\n",
    "- **Зависимость от качества первого кадра**\n",
    "\n",
    "### Рекомендации по улучшению:\n",
    "1. **Добавление предсказания движения** (фильтр Калмана)\n",
    "2. **Использование нескольких детекторов** (ORB + SIFT)\n",
    "3. **Адаптивная настройка параметров** под условия видео\n",
    "4. **Реализация переинициализации** при потере объекта\n",
    "5. **Добавление отслеживания траектории** для сглаживания"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}